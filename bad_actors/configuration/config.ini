[DEFAULT]
logger_name = root
logger_conf_file = configuration/logging.conf
start_date = date('2015-06-07 00:00:00')
end_date = date('2015-06-14 23:59:59')
step_size_in_sec = 691200
#step_size_in_sec = 12960000
#five days in sec = 432000
window_analyze_size_in_sec = 691200
keep_results_for = 2246400
max_concurrent_jobs = 1
domain=Microblog
#domain=Claim
#domain=Blog
#domain=News
#domain=Article
targeted_classes = ['author_type']
#social_network_name = Clickbait_Challenge
#social_network_name = Fake_News
#social_network_name = SBP-BRiMS_2017
social_network_name = Twitter
#social_network_name = PolitiFact
#social_network_url = "https://Clickbait_Challenge.com/"
#social_network_url = "https://SBP-BRiMS_2017.com/"
#social_network_url = "https://politifact.com/"
social_network_url = "https://twitter.com/"


[Logger]
logger_conf_file = configuration/logging.conf
logger_name = root
file_name = log/bad_actors.log
level = logging.INFO

[OperatingSystem]
linux=False
windows=True

[DB]
DB_path = data/input/
DB_name_prefix = bad_actors_
DB_name_suffix = .db
DB_path_to_extension = lib/extension-functions
dialect_name = sqlalchemy.dialects.sqlite

remove_on_setup = False
remove_on_teardown = False
dropall_on_setup = False
dropall_on_teardown = False
start_date = date('2010-01-01 00:00:00')

######################################################################################################
# Impoteres
######################################################################################################

;[XMLImporter]
;xml_path = data/input/XML/

;[CreateAuthorTables]

;[AppImporter] delete
;data_folder = "data/input/watson/"
;bad_actor_threshold = 2
;optional_classes = ["good_actor", "bad_actor"]

;[JSON_Importer]
;actions =["read_from_files"]
;json_path = "C:/DT_Projects/Dataset_from_Dima/TwitterAPI/TwitterTest/parsed/"
;path_bad_actor_csv = C:/DT_Projects/Dataset_from_Dima/Twitter/only_fake.csv
;author_type = bad_actor

;[CsvImporter]
;data_folder = "data/input/datasets/"

# ************** DATASET BUILDER MODULE **********************
[DatasetBuilderConfig]
clean_authors_features_table = False
;
#
[BadActorsCollector]
;actions = ['crawl_bad_actors_followers', 'crawl_bad_actors_retweeters','mark_missing_bad_retweeters']
actions = ['crawl_bad_actors_followers']
targeted_twitter_author_ids = [25073877, 1339835893, 1330457336]
targeted_twitter_post_ids = []
targeted_twitter_author_names = []

;maximal_number_of_retrieved_users = 1000

;[MissingDataComplementor]
;;actions = ['fill_tweet_retweet_connection','fill_data_for_sources','fill_data_for_followers','fill_data_for_friends','fill_authors_time_line'
;;                   ,'assign_manually_labeled_authors','assign_acquired_and_crowdturfer_profiles','delete_acquired_authors','delete_manually_labeled_authors']
;actions = ['fill_tweet_retweet_connection']
;max_users_without_saving = 100
;minimal_num_of_posts = 100
;limit_friend_follower_number = 5
;# maximal_tweets_count_in_timeline maximal value is 200 according to Twitter API
;maximal_tweets_count_in_timeline = 5
;
;[Twitter_Crawler]
;num_of_top_terms = 10
;actions = ['get_most_popular_posts_by_google_trends']
;retrieve_news_by_keywords = []
#[Twitter_Spam_Dataset_Importer]
#original_tsv_location = "data/input/twitter_spam/Manually-Annotated-Tweets.tsv"
#limit_per_crawl = 1000

;[Preprocessor]
;remove_stopwords = True
;apply_stemming = True
;stopwords_file = data/english_stopwords.txt
;stemming_language = en
;is_preprocess_posts = True
;is_preprocess_authors = False
;max_objects_without_saving = 100000

;[TopicDistributionBuilder]

;[LDATopicModel]
;number_of_topics=10
;num_of_terms_in_topic = 12
;stopword_file = lib/eng_stopwords.txt
;stem_language = ENG

;[PostCitationCreator]
;max_number_of_threads = 10000


##################################################################################
###########################Graph Builder##########################################
##################################################################################

#[GraphBuilder_Citation]
#connection_type = citation
#max_objects_without_saving = 100000
;min_number_of_posts_per_author = 1
;num_of_random_authors_for_graph = None

#[GraphBuilder_CoCitation]
#connection_type = cocitation
#max_objects_without_saving = 100000
#min_number_of_cocited_posts = 1
;min_number_of_posts_per_author = 1
;num_of_random_authors_for_graph = None

#[GraphBuilder_Topic]
#connection_type = topic
#max_objects_without_saving = 100000
#min_distance_threshold = 0.2
#min_posts_count = 1
###similarity 0.8
;min_number_of_posts_per_author = 1
;num_of_random_authors_for_graph = None


;[GraphBuilder_Feature_Similarity]
;connection_types = ["topic_distr", "profile_prop"]
;#connection_types = ["profile_prop"]
;#connection_type below should stay empty
;connection_type =
;min_number_of_posts_per_author = 1
;num_of_random_authors_for_graph = None
;max_objects_without_saving = 100000
;topic_distr_features_min_distance_threshold = 1
;topic_distr_features = ["retweet_count", "average_retweets", "average_hashtags", "average_links", "average_user_mentions",
;            "average_post_lenth", "number_of_crawled_posts"]
;
;profile_prop_features_min_distance_threshold = 1
;profile_prop_features = ["account_age", "number_followers", "number_friends" , "friends_followers_ratio" ,
;            "number_of_posts", "default_profile", "default_profile_image",
;            "listed_count", "verified", "screen_name_length", "average_minutes_between_posts",
;            "average_posts_per_day_active_days", "average_posts_per_day_total", "received_retweets_count"]



#[GraphBuilder_Common_Posts]
#connection_type = common_posts
#max_objects_without_saving = 100000
#min_number_of_common_posts = 1
#min_number_of_posts_per_author = 1
;num_of_random_authors_for_graph = None

;[GraphBuilder_Hashtags] check if exists
;connection_type = hashtags
;max_objects_without_saving = 100000
;min_number_of_common_posts = 1
;min_number_of_posts_per_author = 1


;[GraphBuilder_Bag_Of_Words]
;connection_type = bag_of_words
;max_objects_without_saving = 100000
;min_number_of_posts_per_author = 1
;num_of_random_authors_for_graph = None



#[FeatureExtractor]
;table_name = "author_features"
#############################################################################
######################### FEATURE EXTRACTOR MODULES #########################
#############################################################################

;[TopicFeatureGenerator]

;[BehaviorFeatureGenerator]
;feature_list = ["average_minutes_between_posts", "average_posts_per_day_active_days", "average_posts_per_day_total", "retweet_count", "average_retweets", "received_retweets_count"]


;[SyntaxFeatureGenerator]
;feature_list = ["average_hashtags", "average_links", "average_user_mentions", "average_post_lenth" ]


#[AccountPropertiesFeatureGenerator]
;;;feature_list = ["account_age", "number_followers", "number_friends" , "friends_followers_ratio" ,
;;;               "number_of_crawled_posts", "number_of_posts","default_profile","default_profile_image",
;;;               "listed_count","verified", "screen_name_length", "author_screen_name", "author_type", "author_sub_type"]
;feature_list = ["account_age", "author_screen_name", "author_type"]



;[GraphFeatureGenerator_1]
;graph_directed = False
;graph_weights = True
;graph_types = ["cocitation", "common_posts", "topic"]
;#graph_types = ["common_posts"]
;algorithms = ["closeness_centrality", "clustering", "degree_centrality"]
;#algorithms = ["betweenness_centrality", "closeness_centrality", "clustering", "degree_centrality"]
;aggregation_functions = ["mean", "std" ,"kurt", "skew"]
;neighborhood_sizes = [1]
;distances_from_labeled_authors = ["average_distances", "min_distances"]


;[GraphFeatureGenerator_2]
;graph_directed = True
;graph_weights = True
;graph_types = ["citation"]
;algorithms = ["closeness_centrality", "clustering", "in_degree_centrality", "out_degree_centrality"]
;#algorithms = ["betweenness_centrality", "closeness_centrality", "clustering", "in_degree_centrality", "out_degree_centrality"]
;aggregation_functions = ["mean", "std" ,"kurt", "skew"]
;neighborhood_sizes = [1]
;distances_from_labeled_authors = ["average_distances", "min_distances"]


;[AnchorAuthorsCreator]
;targeted_class_num_of_authors_dict = {"good_actor": 100, "bad_actor": 100}
;targeted_class_field_name = 'author_type'
;
;[KNNWithLinkPrediction]
;results_path = data/output/KNNWithLinkPrediction/SNAM_Virtual_TV_Manually_labeled_results_KNN_on_sim_functions.csv
;predictions_per_iteration_path = data/output/KNNWithLinkPrediction/SNAM_Virtual_TV_Manually_labeled_predictions_per_iteration.csv
;k = [1, 2, 3, 4, 5]
;targeted_class_anchors_percent_size= [0.01, 0.02, 0.05, 0.1, 0.2, 0.4]
;similarity_functions = ["common_posts", "topic", "bow", "text_similarity", "profile_similarity",
;                        "posts_content_max_cosine_similarity", "posts_content_max_euclidean_distance",
;                        "posts_content_max_jaccard_similarity", "posts_content_max_manhattan_distance",
;                        "posts_content_max_minkowski_distance", "posts_content_min_cosine_similarity",
;                        "posts_content_min_euclidean_distance", "posts_content_min_jaccard_similarity",
;                        "posts_content_min_manhattan_distance", "posts_content_min_minkowski_distance",
;                        "posts_content_np.mean_cosine_similarity", "posts_content_np.mean_euclidean_distance",
;                        "posts_content_np.mean_jaccard_similarity", "posts_content_np.mean_manhattan_distance",
;                        "posts_content_np.mean_minkowski_distance"
;                        ]
;link_prediction_models = ['jaccard_coefficient']
;order_of_results_dictionary = ['targeted_class_field_name', 'similarity_functions', 'k', 'decision_models','targeted_class_anchors_percent_size']
;#order_of_results_dictionary = ['targeted_class_field_name', 'similarity_functions', 'k', 'decision_models', 'link_prediction_models', 'targeted_class_anchors_percent_size']
;compute_knn_based_on_lp = False
;results_averaged_on_report = True
;generate_anchors = True
;num_iterations = 5
;targeted_class_dict = {"good_actor" : 0, "bad_actor": 1}
;targeted_class_field_name = ['author_type']
;decision_models = ['majority_voting']
;#decision_models = ['majority_voting', 'weighted_majority_voting']
;column_names_for_results_table = ["Targeted_class", "Similarity_function", "K", "Decision_model", "Anchors Percent Size", "Correctly_classified",
;                                    "Incorrectly_classified", "Total", "AUC", "Accuracy", "Precision", "Recall"
;                                 ]
;results_file_name = SNAM_Virtual_TV_Manually_labeled_knn_results.txt
;results_table_file_name = SNAM_Virtual_TV_Manually_labeled_knn_results_table.csv
;path = data/output/KNNWithLinkPrediction/
;index_field_for_predictions = author_screen_name

;[LinkPredictionFeatureExtractor]
;measure_names = ['jaccard_coefficient', 'common_neighbors', 'preferential_attachment',
#'adamic_adar_index', 'total_friends', 'transitive_friends_v1', 'transitive_friends_v2', 'opposite_direction_friends', 'bayesian_promising']
;#measure_names = ['friends_measure']
;aggregation_functions = ['min', 'max', 'mean', 'median', 'skew', 'kurtosis']
;graph_types = {"topic":'undirected', "common_posts": "undirected", "cocitation": "undirected"}
;property_node_field_names = ["author_type"]
;#targeted_class_field_name = author_sub_type
;#optional_classes = ["private", "company", "news_feed", "bot", "spammer"]

;[Kernel_Performance_Evaluator]
;kernels = ['bag_of_words', 'common_posts', 'cocitation', 'topic', 'topic_distr', 'profile_prop']
;index_field_for_predictions = author_screen_name
;path = data/output/Kernel_Performance_Evaluator/

# **************** END FEATURE EXTRACTOR MODULES ******************************
[DataFrameCreator]
all_authors = True
normalize = False

;[DataExporter]
;#arff_file = 'data/output/clickbait_challenge_validation_training_set2.arff'
;arff_file = 'data/output/clickbait_small_training_set.arff'
;#author_type_classes = ["bad_actor", "good_actor"]
;author_type_classes = ["clickbait", "no-clickbait"]

;[Predictor] check if works
;trained_classifier_file_name = 'trained_classifier_author_type_AdaBoost_10_features.pkl'
;best_features_file_name = 'trained_classifier_author_type_AdaBoost_10_selected_features.pkl'
;full_path_trained_classifier_directory = 'data/output/expermintal_environment/trained_classifiers/'
;path = 'data/output/expermintal_environment/'
;targeted_class_field_names = ['author_type']
;replace_missing_values = 'zero'
;indentifier_field_name = 'author_screen_name'
;feature_names_to_remove = ["author_guid", "author_sub_type", "author_screen_name", "set_affiliation"]
;selected_features = []
;targeted_class_dict = {"no-clickbait" : 0, "clickbait": 1}
;classifier_type_name = 'AdaBoost'
;num_of_features = 10


;[ExperimentalEnvironment] change or delete
;perform_k_fold_cross_validation_and_predict = True
;k_for_fold = 10
;classifier_type_names = ["RandomForest", "DecisionTree", "AdaBoost", "XGBoost"]
;#classifier_type_names = ["RandomForest", "DecisionTree", "AdaBoost"]
;selected_features = []
;targeted_class_name = author_type
;removed_features = ["author_sub_type", "author_guid", "author_screen_name"]
;
;#optional_classes = ["good_actor", "bad_actor"]
;optional_classes = ["clickbait", "no-clickbait"]
;;#optional_classes = ["private", "company", "news_feed", "spammer", "bot"]
;index_field = author_screen_name
;#index_field = name
;results_file_name = clickbait_challenge_validation_training_set2_results.txt
;results_table_file_name = clickbait_challenge_validation_training_set2_table.csv
;path = data/output/expermintal_environment/
;backup_path = data\output\results\backup\
;is_rank_influential_features = False
;#num_of_features_to_train = ['all']
;num_of_features_to_train = [5,10,20,'all']
;#num_of_features_to_train = [1,2,3,4,5,6,7,8,'all']
;full_path_model_directory = data/output/expermintal_environment/trained_classifiers/
;order_of_results_dictionary = ['targeted_class_field_name', 'similarity_functions', 'k', 'decision_models', 'link_prediction_models']
;column_names_for_results_table = ["Targeted_class", "Selected_classifier", "Num_of_features", "Correctly_classified",
;                                    "Incorrectly_classified", "Total", "AUC", "Accuracy", "Precision", "Recall"
;                                 ]
;
;predict_on_prepared_clssifier = False
;prepared_classifier_name = trained_classifier_author_type_RandomForest_all_features.pkl
;#targeted_class_name = author_type
;num_of_features = '20'
;classifier_type_name = RandomForest
;train_one_class_classifier_and_predict = False
;train_one_class_classifier_by_k_best_and_predict = False
;
;replace_missing_values = 'zero'
;#replace_missing_values = 'mean'
;
;# delete columns with standard deviation less than this threshold
;stdev_threshold = 0.01
;feature_scaling = ['StandardScaler', 'RobustScaler', 'MinMaxScaler', 'None']
;#feature_scaling = ['None']
;feature_selection = ['f_classif', 'mutual_info_classif']
;############################################################################
;#################Transfer Learning##########################################
;#############################################################################
;transfer_learning = False
;
;#source_domain = 'manually_labeled'
;#source_domain = 'acquired_abusers'
;source_domain = 'honeypot'
;
;#'db': load authors and features from DB table 'authors_features' and train a new model.
;#'csv': load authors with their features from a csv file and trains new model.
;source_input_type = 'csv'
;#source_input_path = 'D:/SOMWEB/documents/Jorge Thesis/arff/[1]manually_good_and_bad_actors/bad_actors_manually_good_and_bad_only.csv'
;#source_input_path = 'D:/SOMWEB/documents/Jorge Thesis/arff/[2]verfied_abusers_and_unlabeled/acquired_dataset.csv'
;source_input_path = 'D:/SOMWEB/documents/Jorge Thesis/arff/[3]honeypot_bots/honeypot.csv'
;
;
;split_percentage = 0.8
;
;transfer_instances = True
;#transfer_algo = 'MODIFIED_BURAK'
;transfer_algo = 'MODIFIED_GRAVITY_WEIGHTING'
;num_neighbors = [1, 2, 3, 4, 5]
;
;#target_domain = 'manually_labeled'
;target_domain = 'acquired_abusers'
;#target_domain = 'honeypot'
;target_input_type = 'csv'
;#target_input_path = 'D:/SOMWEB/documents/Jorge Thesis/arff/[1]manually_good_and_bad_actors/bad_actors_manually_good_and_bad_only.csv'
;target_input_path = 'D:/SOMWEB/documents/Jorge Thesis/arff/[2]verfied_abusers_and_unlabeled/acquired_dataset.csv'
;#target_input_path = 'D:/SOMWEB/documents/Jorge Thesis/arff/[3]honeypot_bots/honeypot.csv
;
;target_train_test_split = 0.8
;#target_train_percent_limit is to keep only this percentage of examples in the training set, simulating a smaller target dataset
;target_train_percent_limit = 0.1
;target_test_percent_limit = 1
;#transfer_instances =False -> executes the same code but without transfering isntances (used to verify it is not transferring instances)
;transfer_instances = True
;transfer_algo = 'GRAVITY_WEIGHTING'
;#transfer_algo = 'BURAK'
;
;#for the BURAK algorihtm, set the number of neares neighbors to transfer, for GRAVITY_WEIGHTING set this value to -1
;#num_neighbors = [1,2,3,4,5,10]
;num_neighbors = [-1]


;[TopicDistrobutionVisualizationGenerator]
;# If it is false you should insert a CSV file under prediction_csv_path
;read_predictions_from_db = False
;include_unlabeled_predictions = True
;include_labeled_authors_in_visualization = True
;targeted_class_field_name = author_type
;optional_classes = {'good_actor': 0, 'bad_actor': 1}
;#prediction_csv_path = "data/output/topic_distribution_visualization/predictions.csv"
;prediction_csv_path = "data/output/topic_distribution_visualization/predictions_on_unlabeled_authors_author_type_XGBoost_all_features.csv"
;output_dir = "data/output/topic_distribution_visualization/"
;buckets = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
[TwitterApiRequester]
consumer_key = "<you'r consumer key>"
consumer_secret = "<you'r consumer secret>"
access_token_key = "<you'r consumer token>"
access_token_secret = "<you'r access token secret>"
user_id = <you'r user id>
screen_name = "<you'r screen name>"

[Twitter_Rest_Api]
#can be 1, 2, or 3
working_app_number = 2
maximal_get_friend_ids_requests_in_window = 15
maximal_get_follower_ids_requests_in_window = 15
maximal_get_user_requests_in_window = 180
maximal_user_ids_allowed_in_single_get_user_request = 100
num_of_requests_without_checking = 9999999999
num_of_twitter_status_id_requests_without_checking = 9999999999
num_of_twitter_timeline_requests_without_checking = 9999999999
maximal_number_of_retrieved_users = 1000

;[TimelineOverlapVisualizationGenerator] check if needed
;common_posts_threshold = 1
;# unlabeled bad author - an author that wasn't manually labeled, i.e. was automatically classified by the model as bad actor
;#unlabeled_bad_authors = ["NewAndroidApps", "PeopleSource_UK", "Niko360","couponsaday", "JuJu_Carbo","LearningroomLMS"]
;# labeled bad author - an author that was manually labeled as bad actor
;#labeled_bad_authors = ["nb95591", "T2Alice", "hjcbizsolutions"]
;output_dir = "overlapping_visualization"
;output_path = "data/output"
;
;;end_date =  ''



